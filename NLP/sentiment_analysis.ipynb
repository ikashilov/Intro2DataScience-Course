{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Sentiment analysis in Russian using LSTM and W2V"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Загрузим датасет твитов на русском с http://study.mokoron.com/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.cm as cm\n",
    "import matplotlib.pyplot as plt\n",
    "from gensim.models import Word2Vec\n",
    "from sklearn.manifold import TSNE\n",
    " \n",
    "''' \n",
    "# Обучим модель W2V\n",
    "logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)\n",
    "\n",
    "data = gensim.models.word2vec.LineSentence('tweets.txt')\n",
    "w2v_model = Word2Vec(data, size=200, window=5, min_count=3, workers=multiprocessing.cpu_count())            \n",
    "'''\n",
    "\n",
    "# Предобученная модель   \n",
    "w2v_model = Word2Vec.load('w2v/tweets_model.w2v')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Функция визуализации слов в пространстве *w2v*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tsne_plot(labels, tokens, classes, clusters):\n",
    "    tsne_model = TSNE(perplexity=15, n_components=2, init='pca', n_iter=3500, random_state=33)\n",
    "    new_values = tsne_model.fit_transform(tokens)\n",
    "\n",
    "    x = []\n",
    "    y = []\n",
    "\n",
    "    for value in new_values:\n",
    "        x.append(value[0])\n",
    "        y.append(value[1])\n",
    "\n",
    "    colors = cm.rainbow(np.linspace(0, 1, num=clusters))\n",
    "\n",
    "    plt.figure(figsize=(16, 9))\n",
    "    \n",
    "    for i in range(len(x)):\n",
    "        plt.scatter(x[i], y[i], c=[colors[classes[i]]], alpha=0.75)\n",
    "        plt.annotate(labels[i], alpha=0.75, xy=(x[i], y[i]), xytext=(5, 2), \n",
    "                     textcoords='offset points', ha='right', va='bottom', size=10)\n",
    "    plt.grid(True)\n",
    "    #plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Выведем для примера по 10 синонимов для каждого из  8 слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "labels = []\n",
    "tokens = []\n",
    "classes = []\n",
    "\n",
    "samples = 8\n",
    "for i, word in enumerate(['виктор', 'прaвый', 'воняешь', 'F#ошибка', 'глаз', 'iphone', 'вкусный', 'нигилизм']):\n",
    "    if word not in w2v_model.wv.vocab:\n",
    "        continue\n",
    "    tokens.append(w2v_model.wv[word])\n",
    "    labels.append(word)\n",
    "    classes.append(i)\n",
    "    for similar_word, similarity in w2v_model.wv.most_similar(word, topn=10):\n",
    "        tokens.append(w2v_model.wv[similar_word])\n",
    "        labels.append(similar_word)\n",
    "        classes.append(i)\n",
    "        \n",
    "\n",
    "tsne_plot(labels, tokens, classes, samples)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Загрузим данные из датасета"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В файлах хранятся размеченные твиты, нас интресует только текст"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "n = ['id', 'date', 'name', 'text', 'typr', 'rep', 'rtw', 'faworite', 'stcount', 'followers', 'friends', 'listcount']\n",
    "data_positive = pd.read_csv('data/positive.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "data_negative = pd.read_csv('data/negative.csv', sep=';', error_bad_lines=False, names=n, usecols=['text'])\n",
    "\n",
    "sample_size = min(data_positive.shape[0], data_negative.shape[0])\n",
    "raw_data = np.concatenate((data_positive['text'].values[:sample_size],\n",
    "                           data_negative['text'].values[:sample_size]), axis=0)\n",
    "\n",
    "labels = [1] * sample_size + [0] * sample_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Отфильтруем данные"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* заменим ё на е  \n",
    "* приведем все к нижнему регистру  \n",
    "* удалим знаки препинания (вообще говоря, нужно не все) \n",
    "* ссылки заменим на тег <\\url>\n",
    "* упоминния пользователей заменим на тег <\\user> \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "def preprocess_text(text):\n",
    "    text = text.lower().replace(\"ё\", \"е\")\n",
    "    text = re.sub('((www\\.[^\\s]+)|(https?://[^\\s]+)|(http?://[^\\s]+))', 'URL', text)\n",
    "    text = re.sub('@[^\\s]+', 'USER', text)\n",
    "    text = re.sub('[^a-zA-Zа-яА-Я1-9:)(;]+', ' ', text)\n",
    "    text = re.sub(' +', ' ', text)\n",
    "    return text.strip()\n",
    "\n",
    "processed_data = [preprocess_text(t) for t in raw_data]\n",
    "#processed_data = raw_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Разделим данные на обучающую и тестовую выборки в соотношении 4/1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x_train, x_test, y_train, y_test = train_test_split(processed_data, labels, test_size=0.2, random_state=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Переведем предложения в вектора слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "DIM = w2v_model.vector_size\n",
    "SENTENCE_LENGTH = 33\n",
    "NUM = 100000\n",
    "\n",
    "def get_sequences(tokenizer, x):\n",
    "    sequences = tokenizer.texts_to_sequences(x)\n",
    "    return pad_sequences(sequences, maxlen=SENTENCE_LENGTH)\n",
    "\n",
    "tokenizer = Tokenizer(num_words=NUM)\n",
    "tokenizer.fit_on_texts(x_train)\n",
    "\n",
    "x_train_seq = get_sequences(tokenizer, x_train)\n",
    "x_test_seq = get_sequences(tokenizer, x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Построение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding\n",
    "from keras.layers import Dense, LSTM, Dropout\n",
    "from keras.layers import SpatialDropout1D, BatchNormalization\n",
    "from keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "\n",
    "# Создаем сеть\n",
    "model = Sequential()\n",
    "model.add(Embedding(NUM, DIM, input_length=SENTENCE_LENGTH, mask_zero=True))\n",
    "model.add(BatchNormalization())\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2, return_sequences=True))\n",
    "model.add(LSTM(50, dropout=0.3, recurrent_dropout=0.3, activation='relu'))\n",
    "model.add(Dense(1, activation=\"sigmoid\"))\n",
    "\n",
    "# Копмилируем модель\n",
    "model.compile(loss='binary_crossentropy',\n",
    "              optimizer='adadelta',\n",
    "              metrics=['binary_accuracy'])\n",
    "\n",
    "# Определим коллбэки для эффекивного обучения\n",
    "checkpoint = ModelCheckpoint(\"frozen-model.hdf5\", monitor='val_binary_accuracy', save_best_only=True, verbose=1)\n",
    "reduce_lr = ReduceLROnPlateau(monitor='val_binary_accuracy', factor=0.9, patience=25, min_lr=0.00001, verbose=1)\n",
    "early_stop = EarlyStopping(monitor='val_binary_accuracy', min_delta=0, patience=0, verbose=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Обучение модели"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Гиперпараметры\n",
    "NUM_EPOCHS = 5\n",
    "BATCH_SIZE = 1024"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Обучаем модель\n",
    "history = model.fit(x_train_seq, y_train,\n",
    "                    batch_size=BATCH_SIZE,\n",
    "                    epochs=NUM_EPOCHS,\n",
    "                    validation_split=0.25,\n",
    "                    verbose=1,\n",
    "                    shuffle=True,\n",
    "                    callbacks = [early_stop, checkpoint, reduce_lr])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Выведем статистику обучения"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pylab as plt\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%pylab inline\n",
    "plt.figure(figsize(10,7))\n",
    "\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('model loss')\n",
    "plt.ylabel('loss')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n",
    "\n",
    "plt.plot(history.history['binary_accuracy'])\n",
    "plt.plot(history.history['val_binary_accuracy'])\n",
    "plt.title('model accuracy')\n",
    "plt.ylabel('accuracy')\n",
    "plt.xlabel('epoch')\n",
    "plt.legend(['train', 'test'], loc='best')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Проверяем качество обучения на тестовых данных\n",
    "scores = model.evaluate(x_test_seq, y_test, batch_size=BATCH_SIZE)\n",
    "\n",
    "print(\"Точность на тестовых данных: %.2f%%\" % (scores[1] * 100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры работы"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обычные высказывания"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "s0 = 'Вообще говоря, мне не по душе этот момент. Ужасно тормозит. стоит дохрена!!! Зря выкинул деньги'\n",
    "s1 = 'Если немного дорабоать, полчится достойная альтернатива iphone'\n",
    "s2 = 'Кусь. Фиговая фигня, но я балдею'\n",
    "s3 = 'Крч, fuck u gays!!!'\n",
    "s4 = 'Ничего не понятно, но в целом неплохо('\n",
    "s5 = 'Когда я первый раз зашел домой, я обрадовался столь плохому освещению'\n",
    "\n",
    "statements = list([s0, s1, s2, s3, s4, s5])\n",
    "\n",
    "filterd_statements = [preprocess_text(t) for t in statements]\n",
    "statements_seq = get_sequences(tokenizer, filterd_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(statements_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.set_printoptions(precision=2)\n",
    "for t in pred:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Примеры отзывов на приложенеие \"Мегафон\" из Google Play"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "m0 = 'глюкопрога ничего не решает, пишет ошибка.'\n",
    "m1 = 'Не могу зайти в личный кабинет,30минут ждала пока загрузится,так и не звгрузился!!!!!'\n",
    "m2 = '''С сегодняшнего дня приложение просто перестало работать. \n",
    "Оператор выслал ссылку по ней все работает. Пробовал переустановить приложение, без результатов.'''\n",
    "\n",
    "m3 = '''верните иконки(виджеты) чтоб можно было вывести на главный экран телефона, \n",
    "очень удобно следить за балансом, и остатком трафика и т.д. не нужно постоянно заходить в личный кабинет. \n",
    "уважаемые разработчики а можно что бы виджеты работали на старых телефонах? у меня один из телефонов андройд 4.2.2. \n",
    "спасибо запонимание.(большая аудитория).у кого дорогие старые телефоны.'''\n",
    "\n",
    "m4 = '''По работе приложения вопросов нет. Перешел на МегаФон с Билайна. \n",
    "И там и там использовал тарифный план с включенными пакетами услуг. \n",
    "И вот на мегафоне решили сделать гениально. Пока есть пакет минут, звонки на все номера (в том числе и мегафон)\n",
    "списываются с пакета включенных минут. А вот когда пакет заканчивается, пожалуйста, звоните на мегафон бесплатно. \n",
    "В качестве информации: на Билайне пакет минут расходуется, только, на разговоры с другими операторами. \n",
    "Пожалел о переходе в первый же день!!!'''\n",
    "\n",
    "m5 = 'ну конечно я не собиралась пистаь этот отзыв но все-таки удобная прога ставлю пять звезд'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "statements = list([m0, m1, m2, m3, m4, m5])\n",
    "\n",
    "filterd_statements = [preprocess_text(t) for t in statements]\n",
    "statements_seq = get_sequences(tokenizer, filterd_statements)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(statements_seq)\n",
    "for t in pred:\n",
    "    print(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
